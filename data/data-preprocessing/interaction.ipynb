{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import json "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 import (preprocessed_data.csv, userid.json, itmeid.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./userid.json') as json_file:\n",
    "    userid = json.load(json_file)\n",
    "    userid = {v: k for k, v in userid.items()}\n",
    "\n",
    "with open('./itemid.json') as json_file:\n",
    "    itemid = json.load(json_file)\n",
    "    itemid = {v: k for k, v in itemid.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = pd.read_csv('./preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data['userid'] = [int(userid[idx]) for idx in preprocessed_data['purchasing_user_profile_id']]\n",
    "preprocessed_data['itemid'] = [int(itemid[idx]) for idx in preprocessed_data['img_url']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 158380 entries, 0 to 158379\n",
      "Data columns (total 18 columns):\n",
      " #   Column                               Non-Null Count   Dtype \n",
      "---  ------                               --------------   ----- \n",
      " 0   purchasing_user_profile_id           158380 non-null  int64 \n",
      " 1   selling_user_profile_profile_url     158377 non-null  object\n",
      " 2   nifty_obj_name                       158380 non-null  object\n",
      " 3   nifty_obj_total_num_editions         158380 non-null  int64 \n",
      " 4   nifty_obj_likes                      158380 non-null  int64 \n",
      " 5   nifty_obj_token_id                   158380 non-null  int64 \n",
      " 6   nifty_obj_timestamp                  158380 non-null  object\n",
      " 7   nifty_obj_contract_address           158380 non-null  object\n",
      " 8   nifty_obj_img_url                    158380 non-null  object\n",
      " 9   nifty_obj_made_user                  158380 non-null  int64 \n",
      " 10  purchasing_user_profile_profile_url  158378 non-null  object\n",
      " 11  selling_user_profile_id              158380 non-null  int64 \n",
      " 12  selling_user_profile_name            157234 non-null  object\n",
      " 13  purchasing_user_profile_name         157241 non-null  object\n",
      " 14  img_url                              158380 non-null  object\n",
      " 15  extension                            155902 non-null  object\n",
      " 16  userid                               158380 non-null  int64 \n",
      " 17  itemid                               158380 non-null  int64 \n",
      "dtypes: int64(8), object(10)\n",
      "memory usage: 21.8+ MB\n"
     ]
    }
   ],
   "source": [
    "preprocessed_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train/test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIN_INTERACTION = 30\n",
    "\n",
    "# agg_on_user = preprocessed_data.groupby(\"userid\").agg({\n",
    "#     \"itemid\": \"nunique\"\n",
    "# })\n",
    "\n",
    "# active_user = agg_on_user[agg_on_user.itemid >= MIN_INTERACTION].index.values\n",
    "# active_df = preprocessed_data[preprocessed_data.userid.isin(active_user)]\n",
    "\n",
    "# # userid itemid 기준으로 unique한 item만 남김\n",
    "# active_df.drop_duplicates(subset=['userid', 'itemid'], inplace=True)\n",
    "\n",
    "# # userid와 nifty_obj_timestamp를 기준으로 정렬\n",
    "# active_df = active_df.sort_values(['userid', 'nifty_obj_timestamp'])\n",
    "# active_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = []\n",
    "# for i in tqdm(range(1, active_df.shape[0])):\n",
    "#     if active_df['userid'][i] == active_df['userid'][i-1]:\n",
    "#         label.append('train')\n",
    "#     else:\n",
    "#         label = label[:-4]\n",
    "#         label.extend(['test']*5)\n",
    "# label = label[:-4]\n",
    "# label.extend(['test']*5)\n",
    "# assert active_df.shape[0] == len(label)\n",
    "# active_df['label'] = label\n",
    "# active_df.to_csv(f\"./active_min{MIN_INTERACTION}.csv\", index=False)\n",
    "# print('active.csv shape: ', active_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = active_df[active_df['label'] == 'train']\n",
    "# train.reset_index(drop=True, inplace=True)\n",
    "# train.to_csv(f\"./train_min{MIN_INTERACTION}.csv\", index=False)\n",
    "# print('train.csv shape: ', train.shape)\n",
    "\n",
    "# test = active_df[active_df['label'] == 'test']\n",
    "# test.reset_index(drop=True, inplace=True)\n",
    "# test.to_csv(f\"./test_min{MIN_INTERACTION}.csv\", index=False)\n",
    "# print('test.csv shape: ', test.shape)\n",
    "# assert active_df.purchasing_user_profile_id.nunique()*5 == test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test answer data 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_answer = test.sort_values(['userid', 'itemid'])[['userid', 'itemid']]\n",
    "# test_answer.to_csv(f\"./test_answer_min{MIN_INTERACTION}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 현재 test의 610개의 item이 train에 존재하지 않는 오류 발생\n",
    "# len(set(test.itemid).difference(set(train.itemid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train/test data split2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_67123/2742962976.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  active_df.drop_duplicates(subset=['userid', 'itemid'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "MIN_INTERACTION = 30\n",
    "\n",
    "agg_on_user = preprocessed_data.groupby(\"userid\").agg({\n",
    "    \"itemid\": \"nunique\"\n",
    "})\n",
    "\n",
    "active_user = agg_on_user[agg_on_user.itemid >= MIN_INTERACTION].index.values\n",
    "active_df = preprocessed_data[preprocessed_data.userid.isin(active_user)]\n",
    "\n",
    "# userid itemid 기준으로 unique한 item만 남김\n",
    "active_df.drop_duplicates(subset=['userid', 'itemid'], inplace=True)\n",
    "\n",
    "# userid와 nifty_obj_timestamp를 기준으로 정렬\n",
    "active_df = active_df.sort_values(['userid', 'nifty_obj_timestamp'])\n",
    "active_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: 310\n",
    "# 1: 261\n",
    "# 2: 227\n",
    "# 7: 193\n",
    "# 8: 191\n",
    "# 32: 179\n",
    "# 39: 148\n",
    "# 197: 146\n",
    "# 309: 114\n",
    "\n",
    "# setseed = 0\n",
    "# leftover = []\n",
    "\n",
    "# while True:\n",
    "\n",
    "#     label = []\n",
    "\n",
    "#     for x in list(active_df.userid.unique()):\n",
    "#         n = active_df[active_df['userid'] == x].shape[0]\n",
    "#         temp = ['train'] * n\n",
    "#         random.seed(setseed)\n",
    "#         five = random.sample(list(range(n)), 5)\n",
    "#         for y in five:\n",
    "#             temp[y] = 'test'\n",
    "#         label.extend(temp)\n",
    "\n",
    "#     assert active_df.shape[0] == len(label)\n",
    "#     active_df['label'] = label\n",
    "\n",
    "#     train = active_df[active_df['label'] == 'train']\n",
    "#     test = active_df[active_df['label'] == 'test']\n",
    "#     left = len(set(test.itemid).difference(set(train.itemid)))\n",
    "#     if not leftover:\n",
    "#         savenew = True\n",
    "#     else:\n",
    "#         if left < min(leftover):\n",
    "#             savenew = True\n",
    "#         else:\n",
    "#             savenew = False\n",
    "#     leftover.append(left)\n",
    "\n",
    "#     if left == 0:\n",
    "#         print(setseed, end=': ')\n",
    "#         train = active_df[active_df['label'] == 'train']\n",
    "#         train.reset_index(drop=True, inplace=True)\n",
    "#         train.to_csv(f\"./train_min{MIN_INTERACTION}.csv\", index=False)\n",
    "\n",
    "#         test = active_df[active_df['label'] == 'test']\n",
    "#         test.reset_index(drop=True, inplace=True)\n",
    "#         test.to_csv(f\"./test_min{MIN_INTERACTION}.csv\", index=False)\n",
    "#         assert active_df.purchasing_user_profile_id.nunique()*5 == test.shape[0]\n",
    "\n",
    "#         test_answer = test.sort_values(['userid', 'itemid'])[['userid', 'itemid']]\n",
    "#         test_answer.to_csv(f\"./test_answer_min{MIN_INTERACTION}.csv\", index=False)\n",
    "#         print(len(set(test.itemid).difference(set(train.itemid))))\n",
    "#         break\n",
    "#     elif savenew:\n",
    "#         print(setseed, end=': ')\n",
    "#         train = active_df[active_df['label'] == 'train']\n",
    "#         train.reset_index(drop=True, inplace=True)\n",
    "#         train.to_csv(f\"./train_min{MIN_INTERACTION}.csv\", index=False)\n",
    "\n",
    "#         test = active_df[active_df['label'] == 'test']\n",
    "#         test.reset_index(drop=True, inplace=True)\n",
    "#         test.to_csv(f\"./test_min{MIN_INTERACTION}.csv\", index=False)\n",
    "#         assert active_df.purchasing_user_profile_id.nunique()*5 == test.shape[0]\n",
    "\n",
    "#         test_answer = test.sort_values(['userid', 'itemid'])[['userid', 'itemid']]\n",
    "#         test_answer.to_csv(f\"./test_answer_min{MIN_INTERACTION}.csv\", index=False)\n",
    "#         print(len(set(test.itemid).difference(set(train.itemid))))\n",
    "#     else:\n",
    "#         setseed += 1\n",
    "\n",
    "#     if setseed == 1000:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터의 item 개수:  7869 개\n",
      "train에 존재하지 않는 test의 item 개수:  7755 중의 114 개\n"
     ]
    }
   ],
   "source": [
    "label = []\n",
    "\n",
    "for x in list(active_df.userid.unique()):\n",
    "    n = active_df[active_df['userid'] == x].shape[0]\n",
    "    temp = ['train'] * n\n",
    "    random.seed(309)\n",
    "    five = random.sample(list(range(n)), 5)\n",
    "    for y in five:\n",
    "        temp[y] = 'test'\n",
    "    label.extend(temp)\n",
    "\n",
    "assert active_df.shape[0] == len(label)\n",
    "active_df['label'] = label\n",
    "\n",
    "train = active_df[active_df['label'] == 'train']\n",
    "test = active_df[active_df['label'] == 'test']\n",
    "\n",
    "train = active_df[active_df['label'] == 'train']\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "train.to_csv(f\"./train_min{MIN_INTERACTION}.csv\", index=False)\n",
    "\n",
    "test = active_df[active_df['label'] == 'test']\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "test.to_csv(f\"./test_min{MIN_INTERACTION}.csv\", index=False)\n",
    "assert active_df.purchasing_user_profile_id.nunique()*5 == test.shape[0]\n",
    "\n",
    "test_answer = test.sort_values(['userid', 'itemid'])[['userid', 'itemid']]\n",
    "test_answer.to_csv(f\"./test_answer_min{MIN_INTERACTION}.csv\", index=False)\n",
    "\n",
    "assert len(train.userid.unique()) == len(test.userid.unique())\n",
    "print('전체 데이터의 item 개수: ', len(set(active_df.itemid)), '개')\n",
    "print('train에 존재하지 않는 test의 item 개수: ', len(set(train.itemid)), '중의', len(set(test.itemid).difference(set(train.itemid))), '개')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction data 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction = pd.pivot_table(train, \n",
    "                             index=[\"userid\"], \n",
    "                             columns=[\"itemid\"], \n",
    "                             values=[\"img_url\"], \n",
    "                             aggfunc=[\"nunique\"],\n",
    "                             fill_value=0)\n",
    "interaction.columns = np.arange(train.itemid.nunique())\n",
    "interaction.reset_index(inplace=True, drop=True)\n",
    "interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity = (interaction.to_numpy() == 0).mean()\n",
    "sparsity, int(sparsity * 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction.to_csv(f\"./train_interaction_min{MIN_INTERACTION}_sparse{int(sparsity * 10000)}.csv\", \n",
    "                   index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intraction과 관련된 json file들 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_interaction_ids(df, id_name):\n",
    "#     interaction_id_dic = pd.DataFrame(\n",
    "#         {id_name: sorted(df[id_name].unique())}\n",
    "#     ).to_dict()[id_name]\n",
    "    \n",
    "#     save_json(f\"interaction_{id_name}\", interaction_id_dic)\n",
    "\n",
    "# def save_json(fname, dic_data):\n",
    "#     with open(f\"./{fname}_min{MIN_INTERACTION}.json\", \"w\") as outfile:\n",
    "#         json.dump(dic_data, outfile, indent=4)\n",
    "\n",
    "def save_interaction_ids(df, id_name):\n",
    "    interaction_id = pd.DataFrame(\n",
    "        {id_name: sorted(df[id_name].unique())}\n",
    "    )\n",
    "    interaction_id_dic = interaction_id.to_json(orient=\"records\")\n",
    "    save_json(f\"interaction_{id_name}\", interaction_id_dic)\n",
    "\n",
    "def save_json(fname, dic_data):\n",
    "\n",
    "    with open(f\"./{fname}_min{MIN_INTERACTION}.json\", \"w\") as outfile:\n",
    "        parsed = json.loads(dic_data)\n",
    "        json.dump(parsed, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemid_imageurl = active_df[['itemid', 'nifty_obj_img_url']]\n",
    "itemid_imageurl = itemid_imageurl.drop_duplicates(subset=[\"itemid\"])\n",
    "itemid_imageurl.set_index('itemid', inplace=True)\n",
    "# itemid_imageurl = itemid_imageurl.to_dict()['nifty_obj_img_url']\n",
    "itemid_imageurl = itemid_imageurl.to_json(orient=\"records\")\n",
    "\n",
    "save_json(\"interaction_itemid_imageurl\", itemid_imageurl)\n",
    "save_interaction_ids(active_df, \"userid\")\n",
    "save_interaction_ids(active_df, \"itemid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
